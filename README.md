# Explaining Automated Refactoring Suggestions

This repository contains the code and documentation for a project focused on explaining automated refactoring suggestions generated by the NSGA-II multi-objective optimization algorithm. The work was conducted during an internship at the ISE-Lab (Feb-June 2019).

The primary goal is to analyze the execution traces of refactoring tools, process the data, classify the refactoring solutions, and extract insights into why certain refactorings are suggested.

## Repository Structure

```
OOPRefactoringPass/
├── data/                     # Raw execution trace data (.txt files, organized by system)
│   ├── ant/
│   │   ├── executiontraces-100.txt
│   │   └── ...
│   ├── jhotdraw/
│   │   └── ...
│   └── ... (e.g., argouml, jfreechart)
├── processed_data/           # Processed and labeled data generated by preprocess_data.py
│   ├── FinalSolutions-multilabel-ant.txt
│   └── ...
├── figs/                     # Generated figures and charts (organized by system)
│   ├── ant/
│   │   ├── ant_num-sol-per-qmood.png
│   │   ├── ant_num-solutions-improving-ge1-qmood.png
│   │   ├── ant_top-20-features-Effectiveness.png
│   │   ├── ...
│   │   └── ant_evaluation_summary.csv
│   └── ...
├── .git/                     # Git repository files
├── preprocess_data.py        # Script for data cleaning, parsing, and preprocessing
├── classification_pipeline.py # Script for classification, feature extraction, and analysis
├── requirements.txt          # Python dependencies
├── README.md                 # This file
# --- Potentially less relevant / Original Files --- #
├── blockFiles/               # Purpose needs clarification
├── feature_ranking/          # Likely contains older feature ranking results
├── important_features.csv    # Potentially outdated summary of important features
├── *.ipynb                   # Original Jupyter notebooks (can be kept for reference)
├── *.sh / *.ps1              # Original helper scripts (can be kept for reference)
```

## Workflow

The analysis follows these main steps using the provided Python scripts:

1.  **Data Preparation:** 
    - Create a `data` directory in the project root.
    - Inside `data`, create subdirectories for each system you want to analyze (e.g., `ant`, `jhotdraw`).
    - Place the raw `.txt` execution trace files for each system into its corresponding subdirectory.

2.  **Data Cleaning and Preprocessing:**
    - Run the `preprocess_data.py` script for *each* system.
    - This script reads traces from `data/<system_name>/`, cleans them, extracts solutions and objective improvements, removes duplicates, and saves the processed data to `processed_data/FinalSolutions-multilabel-<system_name>.txt`.
    ```bash
    python preprocess_data.py <system_name>
    # Example: python preprocess_data.py ant
    ```

3.  **Classification, Evaluation, and Feature Analysis:**
    - Run the `classification_pipeline.py` script for *each* system.
    - This script reads the processed data, trains a multi-label classifier (TF-IDF + LinearSVC) for each quality objective (QMOOD), evaluates performance (Accuracy, Hamming Loss, F1), and generates plots for:
        - QMOOD improvement counts
        - Distribution of improvements per solution
        - Top 20 important features (refactoring operations/locations) for each QMOOD.
    - Plots and evaluation summaries (`.csv`) are saved in `figs/<system_name>/`.
    ```bash
    python classification_pipeline.py <system_name>
    # Example: python classification_pipeline.py ant
    ```

## Setup

1.  **Clone the repository:**
    ```bash
    git clone <repository_url>
    cd OOPRefactoringPass
    ```
2.  **Create a Python virtual environment:** (Recommended)
    ```bash
    python -m venv venv 
    # Activate the environment:
    # Windows: venv\Scripts\activate
    # macOS/Linux: source venv/bin/activate
    ```
3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
4.  **Download NLTK data:** The first time you run `classification_pipeline.py`, it might download the necessary NLTK `stopwords` data.

5.  **Prepare Data:** Organize your raw execution trace files (`.txt`) into the `data/` directory as described above.

## Usage

1.  **Activate virtual environment** (if you created one).
2.  **Run Preprocessing:** Execute `preprocess_data.py` for each desired system:
    ```bash
    python preprocess_data.py ant
    python preprocess_data.py jhotdraw 
    # ... etc.
    ```
3.  **Run Classification Pipeline:** Execute `classification_pipeline.py` for each desired system:
    ```bash
    python classification_pipeline.py ant
    python classification_pipeline.py jhotdraw
    # ... etc.
    ```
4.  **View Results:** 
    - Check `processed_data/` for the cleaned data files.
    - Check `figs/<system_name>/` for generated plots and evaluation summary CSV files.

## Data Format

-   **Input:** Raw execution trace files (`.txt`) located in `data/<system_name>/`. Each pair of lines typically represents a solution (comma-separated refactorings) and its corresponding objective values (comma-separated, within parentheses).
-   **Processed:** Files (`FinalSolutions-multilabel-<system_name>.txt`) in `processed_data/`. Each line contains the cleaned refactoring sequence string followed by the 6 binary QMOOD improvement labels (space-separated, comma-separated numbers, e.g., `... 1, 0, 1, 1, 0, 1`).
